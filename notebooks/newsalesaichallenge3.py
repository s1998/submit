# -*- coding: utf-8 -*-
"""newSalesAiChallenge3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c1bBcddx-SIGApwu2qZsplS0R9mkIZ07
"""

# !pip install transformers flair
# !unzip transcripts-20230117T054959Z-001.zip
# !ls transcripts
# !pip install allennlp==2.1.0 allennlp-models==2.1.0
# !python -m spacy download en_core_web_sm

import spacy
import os, re
nlp = spacy.load('en_core_web_sm') # Load the English Model

all_sents = []

for i, filename in enumerate(sorted(list(os.listdir("transcripts")))[:20]):
  print(i, filename)
  fname = "transcripts/" + filename
  with open(fname, "r") as f:
    txt = f.readlines()
  for l in txt:
    l = l.strip()
    l = " ".join(l.split(":")[1:])
    doc = nlp(l)
    for sent in doc.sents:
      all_sents.append(str(sent))

from allennlp.predictors.predictor import Predictor
import allennlp_models.tagging

predictor = Predictor.from_path("https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz",
                                cuda_device=0)
kk = predictor.predict(
  sentence="Did Uriah honestly think he could beat the game in under three hours?."
)

print(kk)

kk = predictor.predict(
  sentence="Did Uriah honestly think he could beat the game in under three hours?."
)

print(kk)
for s in kk['verbs']:
  print(s)

for i in range(150, 160):
  sent = all_sents[i]
  print(all_sents[i-5:i])
  print(sent)
  kk = predictor.predict(
    sentence=sent)
  for s in kk['verbs']:
    print("    ", s)
  print("\n\n")

processed_sent_context_tuples = []

for i in range(100, 110):
  sent = all_sents[i]
  context_sent = all_sents[i-5:i]
  print(context_sent)
  print(sent)
  kk = predictor.predict(sentence=sent)
  for s in kk['verbs']:
    print("    ", s)
  print("\n\n")

for kk in (predictor.predict(sentence="Do you think we could potentially move the demo to sometime next week, Possibly we could do next Monday."))['verbs']:
  print(kk)

sent = "So is he confirmed for tomorrow, just he hasn't accepted the invite yet?"

for kk in (predictor.predict(sentence=sent))['verbs']:
  print(kk)





len(all_sents)

from tqdm.notebook import tqdm

included_sents = []
for sent in tqdm(all_sents):
  kk = predictor.predict(sentence=sent)
  verbs = kk['verbs']

  times = []
  vbs_lst = []
  for verb in verbs:
    include = False
    for t in verb['tags']:
      if 'tmp' in t.lower():
        include = True

    if include:
      times.append([x for x, y in zip(kk['words'], verb['tags']) if 'tmp' in y.lower()])
      vbs_lst.append(verb["verb"])

  if len(times):
    included_sents.append((times, vbs_lst, sent))

for sent in included_sents[:100]:
  print(sent)



# included_sents[0]



import csv
with open('srlTimeV2.csv','w') as out:
    csv_out=csv.writer(out)
    csv_out.writerow(['label', 'time', 'verbs', 'sentence'])
    for row in included_sents:
        csv_out.writerow((0, row[0], row[1], row[2]))


# pose sequence as a NLI premise and label as a hypothesis
from transformers import AutoModelForSequenceClassification, AutoTokenizer
device = "cuda:0" if torch.cuda.is_available() else "cpu"

nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli').to(device)
tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')

premise = "I am going to USA"
label = "travel"
hypothesis = f'This example is {label}.'

# run through model pre-trained on MNLI
x = tokenizer.encode(premise, hypothesis, return_tensors='pt',
                     truncation_strategy='only_first')
logits = nli_model(x.to(device))[0]

# we throw away "neutral" (dim 1) and take the probability of
# "entailment" (2) as the probability of the label being true 
entail_contradiction_logits = logits[:,[0,2]]
probs = entail_contradiction_logits.softmax(dim=1)
prob_label_is_true = probs[:,1]

premise = "I am going to USA"
label = "travel"
hypothesis = f'This example is {label}.'

# run through model pre-trained on MNLI
x = tokenizer.encode(premise, hypothesis, return_tensors='pt',
                     truncation_strategy='only_first')
logits = nli_model(x.to(device))[0]

# we throw away "neutral" (dim 1) and take the probability of
# "entailment" (2) as the probability of the label being true 
entail_contradiction_logits = logits[:,[0,2]]
probs = entail_contradiction_logits.softmax(dim=1)
prob_label_is_true = probs[:,1]
print(prob_label_is_true)

premise = "I am going to USA"
hypothesis = 'The previous sentence conatains a future task'

curr_sents = [
    "We'll talk soon.",
    "Like, are you guys having meetings next week, and then we can touch base then.",
    "I will send the invite then.",
    "How are you doing?",
    "Oh, it's still really useful.",
    "What was the address again?",
    "But his email then you're were like, let's do it next week. ",
    "I think it's said it's two weak in December.",
    " Again who said you were sick this morning? ",
    "You gotta find some time next week. ",
    "Although next week, you gotta be careful too. ",
    "Placing see again."
]

for premise in curr_sents:
  # run through model pre-trained on MNLI
  x = tokenizer.encode(premise, hypothesis, return_tensors='pt',
                      truncation_strategy='only_first')
  logits = nli_model(x.to(device))[0]

  # we throw away "neutral" (dim 1) and take the probability of
  # "entailment" (2) as the probability of the label being true 
  entail_contradiction_logits = logits[:,[0,2]]
  probs = entail_contradiction_logits.softmax(dim=1)
  prob_label_is_true = probs[:,1].detach().item()
  print(premise, prob_label_is_true)



premise = "I am going to USA"
hypothesis = 'The previous sentence conatains a future task'

new_included_sents = []

for curr in included_sents[:100]:
  _, _, premise = curr
  # run through model pre-trained on MNLI
  x = tokenizer.encode(premise, hypothesis, return_tensors='pt',
                      truncation_strategy='only_first')
  logits = nli_model(x.to(device))[0]

  # we throw away "neutral" (dim 1) and take the probability of
  # "entailment" (2) as the probability of the label being true 
  entail_contradiction_logits = logits[:,[0,2]]
  probs = entail_contradiction_logits.softmax(dim=1)
  prob_label_is_true = probs[:,1].detach().item()
  # print(premise, prob_label_is_true)
  new_included_sents.append((prob_label_is_true, curr[2], curr[0], curr[1]))

sorted(new_included_sents, reverse=True)



premise = "I am going to USA"
hypothesis = 'The previous sentence conatains a future task'

new_included_sents = []

for curr in tqdm(included_sents):
  _, _, premise = curr
  # run through model pre-trained on MNLI
  x = tokenizer.encode(premise, hypothesis, return_tensors='pt',
                      truncation_strategy='only_first')
  logits = nli_model(x.to(device))[0]

  # we throw away "neutral" (dim 1) and take the probability of
  # "entailment" (2) as the probability of the label being true 
  entail_contradiction_logits = logits[:,[0,2]]
  probs = entail_contradiction_logits.softmax(dim=1)
  prob_label_is_true = probs[:,1].detach().item()
  # print(premise, prob_label_is_true)
  new_included_sents.append((prob_label_is_true, curr[2], curr[0], curr[1]))



import csv
with open('srlTimeV3.csv','w') as out:
    csv_out=csv.writer(out)
    csv_out.writerow(['label', 'probab', 'sentence', 'time', 'verbs'])
    for row in sorted(new_included_sents, reverse=True):
        csv_out.writerow((1, row[0], row[1], row[2], row[3]))

