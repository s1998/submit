# -*- coding: utf-8 -*-
"""sailesAiChalleng.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uQBhqKMco3uRMvhWMyX_BvugA4hc8fOo
"""

# !pip install transformers flair
# !unzip transcripts-20230117T054959Z-001.zip
# !ls transcripts

fname = "transcripts/639234e4a39c8c8e9c03759c.txt"

with open(fname, "r") as f:
  txt = f.readlines()

import os, re
import spacy
nlp = spacy.load('en_core_web_sm') # Load the English Model

all_sents = []
for i, filename in enumerate(sorted(list(os.listdir("transcripts")))[:20]):
  print(i, filename)
  fname = "transcripts/" + filename
  with open(fname, "r") as f:
    txt = f.readlines()
  for l in txt:
    l = l.strip()
    if l.startswith("Client"):
      l = re.sub("Client [0-9]*:","", l,count=1)
      doc = nlp(l)
      for sent in doc.sents:
        all_sents.append(str(sent))

# reference code of zero-shot classification pipeline from flair
# # !pip install flair
# from flair.models import TARSClassifier
# from flair.data import Sentence
# # 1. Load our pre-trained TARS model for English
# tars = TARSClassifier.load('tars-base')
# # 2. Prepare a test sentence
# sentence = Sentence("I am so glad you liked it!")
# # 3. Define some classes that you want to predict using descriptive names
# classes = ["happy", "sad"]
# #4. Predict for these classes
# tars.predict_zero_shot(sentence, classes)
# # Print sentence with predicted labels
# print(sentence)


from transformers import pipeline

title = "Zero-Shot Text Classification with Hugging Face"
description = "bart-large-mnli"
classifier = pipeline("zero-shot-classification",
                      model="facebook/bart-large-mnli", device=0)

#define a function to process your input and output
def zero_shot(doc, candidates):
    given_labels = candidates.split(", ")
    dictionary = classifier(doc, given_labels)
    labels = dictionary['labels']
    scores = dictionary['scores']
    return dict(zip(labels, scores))

# # some examples to see if its working
# aa = ["How are you?", "Right?", "Could you let me know this", "Cool", "Good", "Good day"]
# for x in aa:
#   print(x, zero_shot(x, "question, statement"))

from tqdm.notebook import tqdm
questions, statements = [], []

for i in tqdm(range(len(all_sents) // 100)):
  curr_sents = all_sents[i*100:(i+1)*100]

  x = classifier(curr_sents, ["question", "statement"])
  for xx in x:
    if xx['labels'][0] == 'question':
      questions.append((xx['sequence'], xx['scores'][0]))
    else:
      statements.append((xx['sequence'], xx['scores'][0]))

import csv
with open('questions.csv','w') as out:
    csv_out=csv.writer(out)
    csv_out.writerow(['sent','score', 'label'])
    new_ques = list(set([t for t in questions if ("question" not in t[0].lower() and len(t[0].split()) > 3)]))
    for row in sorted(new_ques, key=lambda x: x[1], reverse=True):
        csv_out.writerow((row[0], row[1], -1))

import csv
with open('statements.csv','w') as out:
    csv_out=csv.writer(out)
    csv_out.writerow(['sent','score', 'label'])
    new_ques = list(set([t for t in statements if ("question" not in t[0].lower() and len(t[0].split()) > 3)]))
    for row in sorted(new_ques, key=lambda x: x[1], reverse=True):
        csv_out.writerow((row[0], row[1], -1))

# sorted([t for t in questions if "question" not in t[0].lower()], key=lambda x: x[1], reverse=True)[:50]
# sorted([t for t in statements if "question" not in t[0].lower()], key=lambda x: x[1], reverse=True)[:50]
# [t for t in questions if ("question" not in t[0].lower() and len(t[0].split()) > 2)][200:250]






