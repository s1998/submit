Client 2: he's in family of the team flow group. So you for having.

Host 1: Great. Totally. Alright. Let me catch you up on the issues that we're having here. So can you see my screen here?

Client 2: Yes.

Host 1: So this is Cell Ai. So the the the idea again, is pretty straightforward we can see here my meeting recordings. And let me take a good example here, I believe if this this is going to be a fine one. And so I can click on any meeting. I can look at the recording Is this how many workspaces is a transcript generated by Deepgram And here, I can I can connect I can see a summary that basically we feed this transcript to W three. We generate summary from of the meeting. And then, you know, the user can actually duck to an Ai about conversation like, hey, like know, what is it solution about? Like, what was the outcome installed in forth? What we are discovering is that The the transcript quality... We're having issues with the transcript approved quality. Especially, I I suspect that lot that's actually due to my accent. I think think it's struggling quite a bit with accents. And I'm looking for like pulled in that because this is actually not the best. Mh. Perhaps these Yeah. I think even even with American accents it's very often as struggling. So And the problem is that again, we... We are fitting that to Ai instead of like garbage and get a garbage out. And so as a result of this, you know, the the summary is bad, like, the the the Ai chat is bad and so on into until So, yeah, just went to see if you had any suggestions on how to get better results. Yeah.

Client 3: So you know, First of all, what we always wanna do is is just take a scientific approach if you can provide the audio to combine provide the corresponding transcripts. Information is helpful to us to understand exactly what's going wrong. Right? When you say something like you know, they're they're not great on my accent. Right? What does that mean? Is it not picking of any words it picking up some words, Is it missing specific words? Right? So so identifying exactly what's going wrong is going to be the first step that we're gonna wanna take. The second step we're gonna wanna take is if this is something that we can pick up very quickly through model training. Basically, what we would do is we would take some representative audio let's in your in, which I understand, probably we not representative but everyone using sales ai. But we just get data from it. And we normalize against just a general set of audio meaning all audio all invoices. But we train on some of yours. We can improve on your specific accent and then give you a model that's more generally so you don't get negative you know, accuracy against our base model. But we also improved greatly the accuracy your accent or others like yours. Does that make sense?

Host 1: Yeah. The problem is that obviously, we're not be able to customer, and and we'd rather avoid having to go through entire training room. Even if we could we'd would rather avoid throwing a away to feel meetings because, like, that's why like the the impression of the meaning of the of the of the product is is full This is another example of a meeting. So just to characterize very clearly The issue again. So, yeah. It basically... Guys. Yeah. I spent like a semester and france long ago in game mobile. But I wanna go to. Okay. What what were are doing called that? Physics I was a physics researcher, so it semester. Oh, wow. Nice Right. So here it's it's like message reading the Nice It's... It he also has an accent, which i think is the other issue that he's got like, a russian accent, but it's it's basically, I think more than half the world all incorrect. I don't know does last. Right. Just... Yeah. So... Yeah. That... That's the issue we're having here. So is there any solution here about, like, retraining the mobile but like can you be license?

Client 3: So so there's two things here. Right? Because what you're pointing out is that the words are distributed incorrectly to the speaker. Which i deem is different than the words being incorrect. Right?

Client 3: So which we're discussing Go ahead.

Host 1: That does both issues.

Host 4: I think the are incorrect as well Like if you looked it's Soogrim does deal last year, on the screen think. I said I moved here last year, so it's quite different on its. She coming me back my Correct.

Host 1: My name is very.

Host 1: That's here. I it used to be in the bay area nine who does last here.

Client 3: Okay. Yeah. So I think you know, The the first thing is if these are multi channel recordings, which I don't know what they are you can actually separate based on channel and then you're essentially going to have this as a perfect separation. Because everyone every word that, like, flow says will be a transcript dedicated to flow and everywhere in that sergei will be a transcript dedicated to Sergei. So that's another approach if you do have channel separated audio. Otherwise, dia is doing its best to essentially assign the speakers and that's maybe a little bit different than explicitly just the words being wrong. That's more of a dia russian. And then I'd kind of ask you more questions than that route. In terms of the accuracy, I know it's not ideal for me to suggest a model train and I wouldn't fact that we would want to retrain for every single customer. But maybe some initial training just based on your meetings, the subject context of your meetings. Because we're not just training on your accents. We're also training on the audio context and the specific things being spoken here. So the conversations that you're going to be having are going to be different in the conversations that call center might be having or equivalent. Right? Because they're more sales focused. The other thing is we just have to understand which parameters you're using though. I believe you're using the model. So that shouldn't be you know, blocker in terms of you getting our best accuracy. Are using, you know, enhanced phone call or in enhanced general? Can you share maybe more about that?

Host 1: I'm believe using enhanced general D know ian?

Host 4: Sorry. It was muted. Yeah. I think were using it in enhanced we're using some something that's think it's in i general and I think we're using some enhanced dia sterilization as well.

Client 3: Okay. If you can just confirm that, maybe try being hands phone calls well these are more kind of like, phone call meetings. That that's under avenue, you can take that might be a better model.

Host 4: Separately.

Client 3: They and really come from video conferencing like Zoom and google needs.

Host 4: I think those are the main two. So with that what phone call apply to that, In might don't know how literally is the phone call thing, but I don't think.

Host 4: It's more low low band audio.

Client 3: Not specific explicitly phone call. It's more just aligned to low band. So you, I don't know how you're pulling the recordings, But if they are like, hey k Eight kilohertz eight thousand kilohertz. Then, you know, that might be something where the phone come on might be more performant.

Host 1: Doesn't sound like recording to me.

Client 3: Does it? Yeah.

Client 3: From from this. This one does.

Host 1: So... Okay. So check, please recall with the recordings or eight k. I think should also check with them. We can have channel based recordings like multi channel recordings.

Client 3: Yeah.

Client 3: Those those are two good shops to start with. And then I'd also just ask, you know, again, I wouldn't necessarily recommend you do model every single customer though you might want to do strategic ones especially if you have, like, a large customer work a large portion of revenue or whatever. Models tend to perform very well. Because you're training on their specific context verbiage terminology spellings, etcetera. Sound environment acoustic environment. What I might suggest though is just a small you in model train. Just so you can see for yourself based on your audio, and your representative conversations. We can whip one up that's, you know, not broader than maybe this more specific use case, if it seems like this is more interview type conversations you know, we we could train on that. And and you would probably see a pretty significant improvement based on being more inclusive of this specific accents and the specific terminology being discussed in these conversations.

Host 4: It's training with we need a transcript that's been corrected. If there any missing words and anything that.

Client 3: Yeah. Great question. No. You would just provide us the audio. So it would just be representative audio. So, you know, this is an example you know, audio that you'd be running the meeting software on you would pull this audio file or video file. Just the original one wouldn't want you to compress it or change in any way because, essentially, what we're training on is also going to be improving on. So I would say, you know, ten and least hours it's a representative audio, if you can provide twenty, that'd be much much better. We will do the labeling and output a model to you. That is let's say, a model equals steam flow. And then you wouldn't even have to worry about, you know, phone call or general because we basically validate that on our end, make sure we identify which one is more performant. And then output a model to you. That is just model equals steam flow tier equals hands. That kind of takes care of all of that altogether and is better on this a big accents and terminology that you discuss.

Host 1: But again, I I don't assume that this would transfer this kind of like the performance games would trans to a look would it So it it does depend.

Client 3: Right? If your other having some more conversations for this or some more accents. Then it very much would transfer because it's training on not just, you know, your accent, but you features of your accent, the acoustic environment of your accent, the terminology of your accent.

Client 3: Don't think I don't think they are having similar positions neither on the x on the topic.

Host 1: And and I I think you're also having, like, issues with the transcriptions as well.

Host 1: I mean, if you wanna send this representative audio from them, could train a model specifically for the customer as well.

Client 3: Right? And and again, I'm not saying the you trip to for every single customer, but getting a baseline of some the amount of hours of trouble audio and don't just buy as towards the trouble audio also give us maybe we also do quite well out because we wanna just get a baseline of here's the type of things that are discussed. Here's the type of accents involved here the type of room environment or acoustic environment, Right? Is it two speakers is the four speakers six speakers. All of that data goes in and we output a model for you. That is, you know, more bias towards getting that information directly.

Host 1: Have a dumb question. Jot thomas from Loom is He was telling me that they were experimenting quite a bit right now Based transcription and they're were having extraordinary results based on that. Like, this is, like, blew up, like all of their benchmarks. Is that something that Deepgram is is currently looking at?

Client 3: Yeah. We've looked at whisper. Soogrim our Ceo as a big blog post about it. Broadly speaking, there's a few different faults with Whisper. And, you know, I I could get into it if it's relevant to you here, but We looked at it and based on our findings we found that we out perform on the number of benchmarks. The other thing that Whisper doesn't have going for? Is real time transcription, which it doesn't currently do. Whisper does not have timestamps stamps. Might make some of your transcript logic a little bit more difficult. And Whisper is also much slower. You've probably noticed in running Deepgram it outputs the results very quickly whereas W takes a bit of time longer. And all that's based on the approach. So we've kind patented in our approach. Has been proven to be a lot more computer efficient and has a lot of other benefits.

Client 3: I get close to the approach that we've taken.

Host 1: How much slower is we pure because In case, you know, i i I actually think colleagues is a lot more important in than speed. For now, at least yeah.

Client 3: Damn. I'm absolutely. Here is the blog post It has information about the speed about the accuracy, about the different models, we set to all five models, the tiny of the base small the medium in the orange. And the speeds as well. Relative each model.

Client 5: One one thing to add is that our research team actually has worked on getting whisper into our system and also supporting the features that we have. So, like the know, if if you were to download Whisper off the shelf right now, you wouldn't get timestamps stamps and and features that work with Deepgram essentially. We are working to make that available to customers and that should be ready and January, maybe even as soon as next week. So some datasets we actually have seen that whisper out forms our model like Sam on others and some of the internal benchmarks that we've done. We've form them. So it kinda depends on the dataset But we will have that option available and, like, fully featured for our customers. There are some implications around the compute side of it, like, same was mentioning like an hour you know, or a thirty minute phone call for Deepgram would take like, fifteen, twenty seconds to return to you for for what spur depending on the model that you're running it could take anywhere between, like, thirty minutes in a few hours. But if that's not a problem, you're getting better accuracy and you want, like, the time stamps and other features like that. Like, you know, dia or multi channel to, like, just work. As opposed to getting it off the shelf yourself. That's that's something that we could discuss probably relatively soon, have you be one of our early testers with that Yeah.

Host 1: I'd love... I have to at least like run own benchmarks on against like, this this kind of transcript, for example, and and see the kind of results that we're getting. I'm wondering if there would be workaround workarounds to the the timestamp issues, for example Like, maybe if you run it like your old model, and then you use the thermostat the them for you from your model, but the transcripts from voice pure, this is disconnects stuff Yeah.

Client 5: So the the work... Like the the things that we've been doing on our end is getting our like, feature set to to work with Whisper. So, like, what you get with Deepgram enhanced model, you would also get with Whisper in terms of, like the time and other features that are supported. So that's been kind of the the lift of what the the research team is been doing, and then we gotta put it in production.

Host 1: And and when do you think that be a available for testing?

Client 5: As soon as next week as late as, like, end of January, So pretty...

Host 1: I I'd love to say up for the bit that definitely like Okay.

Client 5: Sounds good. But we'll definitely let you know, like, right when something's released and and in production we'll we'll let you know.

Host 1: Sweet. Awesome. Okay. So I'll follow up in a week about whisper and the the the bit out of that model. Great. Anything else we So on our side, I think Yeah. We're going to send you a bunch of of our audio. I I would love to get like, that just model we mentioned. I think we also need to talk without bot because we don't do the recording all sales we we go through a partner that's called a recall. You might get have hell of him. And I I am all impression that it might be doing some wrong with the recording. I'm person to make. They might not do it like a multi general recording and it might do it like an kind of recording. So like, we need we need to check with them what's going on here. Anything else we can do here.

Client 3: Offhand. You know I'd always recommend Just testing it out testing some of the other parameters.

Client 3: You've mentioned you've only to general. Phone calls a good shout as well. Recall, you know, that's probably a good place to start to figure out if the recording are changing in any way from, you know, the initial to the recording you know, any type of compression you're doing is helpful as a reference point as well. And the model training is really going to be the one that's going to be the fast this, you know, improvement that you're going to see. Because again, if we're training on the specific representative audio, we're going to improve significant on that audio. And middle yield up you know, pretty substantial improvement.

Host 1: Great. Awesome. Okay? Okay. So if me follow by email then with do list of of these action items. Ian will be able to to point on them. So again, setting your audio and, you know, testing a few more parameters like playing around with with this, basically. And we can take it from there.

Client 3: Yes. Sounds great. Just quickly while I have you both Should we book time for next week to check in? Or ian are you planning on sending the audio I mean, should I just check with ian in a week? Like, like, what's the best plan there?

Host 1: Yeah. How much could do that by email. What what do you think ian?

Host 4: Yeah. Should we just do that on the existing email for and then we can because we'll going ask some questions to partner or about some of the things and and see how much audio we've got so far to give you training in the something.

Client 3: Sounds. Works. Yeah. So whenever you get that, send it over, I'll pull it down and send it to our research seem to make that model and then we deploy the model especially for you. So like, only your project. So one of the other things you might wanna look into giving me is the email that you're using the project Id that you're using Typically, we also segment access to models by the project Id, and you can invite members into the project. So that's another thing that you might wanna think about is if you have, like, an overarching team project make sure everyone that would be testing the model is in that project.

Host 4: Okay. So Yeah. When you say everyone who would be tested in that model Do you mean because we have a project Id and we use the Api to send audio that. So you just mean that we're sending everything to that right. So that's to the same project.

Client 3: To that project. Yeah. You can make multiple Api keys. You can make multiple email accounts associated to one project, but we're going to give access to that model we have to a project Id.

Client 3: So just make sure that yeah. Anyone who's testing it is part of that project Id. Yep. Cool Alright?

Host 1: Great. Okay. I'm following up then by email and we can take it from there.

Client 3: Sounds good. Pleasure meeting both. Thank you for their time.

Host 1: Thank you as well. So yep.

Host 4: Yep. Thank you. It